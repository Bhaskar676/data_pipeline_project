version: '3.8'

services:
  # PostgreSQL for Airflow metadata
  postgres:
    image: postgres:13
    environment:
      POSTGRES_USER: airflow
      POSTGRES_PASSWORD: ${POSTGRES_PASSWORD:-airflow}
      POSTGRES_DB: airflow
    volumes:
      - postgres_db_volume:/var/lib/postgresql/data
    healthcheck:
      test: ["CMD", "pg_isready", "-U", "airflow"]
      interval: 5s
      retries: 5
    restart: always
    ports:
      - "5432:5432"

  # Data warehouse PostgreSQL
  postgres_dw:
    image: postgres:13
    environment:
      POSTGRES_USER: dataeng
      POSTGRES_PASSWORD: ${POSTGRES_DW_PASSWORD:-dataeng123}
      POSTGRES_DB: news_warehouse
    volumes:
      - postgres_dw_volume:/var/lib/postgresql/data
      - ./init-warehouse.sql:/docker-entrypoint-initdb.d/init-warehouse.sql
      - ./init-movielens.sql:/docker-entrypoint-initdb.d/init-movielens.sql
    healthcheck:
      test: ["CMD", "pg_isready", "-U", "dataeng"]
      interval: 5s
      retries: 5
    restart: always
    ports:
      - "5433:5432"

  # Airflow webserver
  airflow-webserver:
    image: apache/airflow:2.7.0-python3.10
    environment:
      AIRFLOW__CORE__EXECUTOR: LocalExecutor
      AIRFLOW__DATABASE__SQL_ALCHEMY_CONN: postgresql+psycopg2://airflow:airflow@postgres/airflow
      AIRFLOW__CORE__SQL_ALCHEMY_CONN: postgresql+psycopg2://airflow:airflow@postgres/airflow
      AIRFLOW__CORE__FERNET_KEY: '${AIRFLOW_FERNET_KEY:-Wb2wbqOTpeiGYalyIxtnnDXfVOqJLk_lGksM6s_JTRU=}'
      AIRFLOW__CORE__DAGS_ARE_PAUSED_AT_CREATION: 'false'
      AIRFLOW__CORE__LOAD_EXAMPLES: 'false'
      AIRFLOW__API__AUTH_BACKENDS: 'airflow.api.auth.backend.basic_auth'
      AIRFLOW__SCHEDULER__ENABLE_HEALTH_CHECK: 'true'
      AIRFLOW__WEBSERVER__EXPOSE_CONFIG: 'true'
      AIRFLOW__WEBSERVER__AUTHENTICATE: 'true'
      AIRFLOW__WEBSERVER__AUTH_USER_REGISTRATION: 'false'
      # Email alerts configuration
      AIRFLOW__EMAIL__EMAIL_BACKEND: 'airflow.utils.email.send_email_smtp'
      AIRFLOW__SMTP__SMTP_HOST: '${SMTP_HOST:-smtp.gmail.com}'
      AIRFLOW__SMTP__SMTP_PORT: '${SMTP_PORT:-587}'
      AIRFLOW__SMTP__SMTP_USER: '${SMTP_USER:-}'
      AIRFLOW__SMTP__SMTP_PASSWORD: '${SMTP_PASSWORD:-}'
      AIRFLOW__SMTP__SMTP_MAIL_FROM: '${SMTP_MAIL_FROM:-}'
      AIRFLOW__SMTP__SMTP_SSL: '${SMTP_SSL:-False}'
      AIRFLOW__SMTP__SMTP_STARTTLS: '${SMTP_STARTTLS:-True}'
      # Slack alerts configuration
      AIRFLOW__SLACK__SLACK_WEBHOOK_CONN_ID: 'slack_webhook'
      # Default alert settings
      AIRFLOW_USERNAME: ${AIRFLOW_USERNAME:-airflow}
      AIRFLOW_PASSWORD: ${AIRFLOW_PASSWORD:-airflow123}
      AIRFLOW_EMAIL: ${AIRFLOW_EMAIL:-admin@example.com}
      _PIP_ADDITIONAL_REQUIREMENTS: 'requests beautifulsoup4 psycopg2-binary pandas numpy apache-airflow-providers-slack'
    volumes:
      - ./dags:/opt/airflow/dags
      - ./logs:/opt/airflow/logs
      - ./plugins:/opt/airflow/plugins
      - ./scripts:/opt/airflow/scripts
      - ./data:/opt/airflow/data
    user: "${AIRFLOW_UID:-50000}:0"
    ports:
      - "8080:8080"
    command: >
      bash -c "
        airflow db init &&
        airflow users create --username $$AIRFLOW_USERNAME --firstname Admin --lastname User --role Admin --email $$AIRFLOW_EMAIL --password $$AIRFLOW_PASSWORD &&
        airflow webserver
      "
    depends_on:
      postgres:
        condition: service_healthy
    restart: always
    healthcheck:
      test: ["CMD", "curl", "--fail", "http://localhost:8080/health"]
      interval: 10s
      timeout: 10s
      retries: 5

  # Airflow scheduler
  airflow-scheduler:
    image: apache/airflow:2.7.0-python3.10
    environment:
      AIRFLOW__CORE__EXECUTOR: LocalExecutor
      AIRFLOW__DATABASE__SQL_ALCHEMY_CONN: postgresql+psycopg2://airflow:airflow@postgres/airflow
      AIRFLOW__CORE__SQL_ALCHEMY_CONN: postgresql+psycopg2://airflow:airflow@postgres/airflow
      AIRFLOW__CORE__FERNET_KEY: '${AIRFLOW_FERNET_KEY:-Wb2wbqOTpeiGYalyIxtnnDXfVOqJLk_lGksM6s_JTRU=}'
      AIRFLOW__CORE__DAGS_ARE_PAUSED_AT_CREATION: 'false'
      AIRFLOW__CORE__LOAD_EXAMPLES: 'false'
      AIRFLOW__API__AUTH_BACKENDS: 'airflow.api.auth.backend.basic_auth'
      AIRFLOW__SCHEDULER__ENABLE_HEALTH_CHECK: 'true'
      AIRFLOW__WEBSERVER__EXPOSE_CONFIG: 'true'
      AIRFLOW__WEBSERVER__AUTHENTICATE: 'true'
      AIRFLOW__WEBSERVER__AUTH_USER_REGISTRATION: 'false'
      # Email alerts configuration
      AIRFLOW__EMAIL__EMAIL_BACKEND: 'airflow.utils.email.send_email_smtp'
      AIRFLOW__SMTP__SMTP_HOST: '${SMTP_HOST:-smtp.gmail.com}'
      AIRFLOW__SMTP__SMTP_PORT: '${SMTP_PORT:-587}'
      AIRFLOW__SMTP__SMTP_USER: '${SMTP_USER:-}'
      AIRFLOW__SMTP__SMTP_PASSWORD: '${SMTP_PASSWORD:-}'
      AIRFLOW__SMTP__SMTP_MAIL_FROM: '${SMTP_MAIL_FROM:-}'
      AIRFLOW__SMTP__SMTP_SSL: '${SMTP_SSL:-False}'
      AIRFLOW__SMTP__SMTP_STARTTLS: '${SMTP_STARTTLS:-True}'
      # Slack alerts configuration
      AIRFLOW__SLACK__SLACK_WEBHOOK_CONN_ID: 'slack_webhook'
      # Default alert settings
      AIRFLOW_USERNAME: ${AIRFLOW_USERNAME:-airflow}
      AIRFLOW_PASSWORD: ${AIRFLOW_PASSWORD:-airflow123}
      AIRFLOW_EMAIL: ${AIRFLOW_EMAIL:-admin@example.com}
      _PIP_ADDITIONAL_REQUIREMENTS: 'requests beautifulsoup4 psycopg2-binary pandas numpy apache-airflow-providers-slack'
    volumes:
      - ./dags:/opt/airflow/dags
      - ./logs:/opt/airflow/logs
      - ./plugins:/opt/airflow/plugins
      - ./scripts:/opt/airflow/scripts
      - ./data:/opt/airflow/data
    user: "${AIRFLOW_UID:-50000}:0"
    command: airflow scheduler
    depends_on:
      postgres:
        condition: service_healthy
      airflow-webserver:
        condition: service_healthy
    restart: always
    healthcheck:
      test: ["CMD-SHELL", 'airflow jobs check --job-type SchedulerJob --hostname "$${HOSTNAME}"']
      interval: 10s
      timeout: 10s
      retries: 5

volumes:
  postgres_db_volume:
  postgres_dw_volume: 